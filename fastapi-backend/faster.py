import time
import queue
import threading
import numpy as np
import sounddevice as sd
from faster_whisper import WhisperModel

# -------- Settings (à¦¸à¦¹à¦œà§‡ à¦¬à¦¦à¦²à¦¾à¦¤à§‡ à¦ªà¦¾à¦°à¦¬à§‡à¦¨) --------
MODEL_SIZE   = "base"     # tiny / base / small / medium
LANGUAGE     = None       # None = auto, à¦¬à¦¾ "bn" / "en" à¦¦à¦¿à¦¨
SAMPLE_RATE  = 16000      # faster-whisper 16kHz à¦­à¦¾à¦²à§‹ à¦•à¦¾à¦œ à¦•à¦°à§‡
FRAME_MS     = 250        # à¦ªà§à¦°à¦¤à¦¿ 250ms à¦•à¦°à§‡ à¦®à¦¾à¦‡à¦• à¦¥à§‡à¦•à§‡ à¦«à§à¦°à§‡à¦® à¦¨à§‡à¦¬
PROCESS_EVERY_SEC = 0.8   # à¦•à¦¤à¦•à§à¦·à¦£ à¦ªà¦°à¦ªà¦° à¦Ÿà§à¦°à¦¾à¦¨à§à¦¸à¦•à§à¦°à¦¾à¦‡à¦¬ à¦šà¦¾à¦²à¦¾à¦¬
ROLLING_WINDOW_SEC = 8.0  # à¦¶à§‡à¦· à§® à¦¸à§‡à¦•à§‡à¦¨à§à¦¡ à¦…à¦¡à¦¿à¦“à¦¤à§‡ à¦°à¦¾à¦¨ à¦•à¦°à¦¬
# -------------------------------------------------

def load_model():
    """
    CUDA à¦¥à¦¾à¦•à¦²à§‡ FP16, à¦¨à¦¾ à¦¹à¦²à§‡ CPU int8/float32-à¦ fallback.
    """
    try:
        import torch
        if torch.cuda.is_available():
            print("[model] CUDA detected â†’ FP16")
            return WhisperModel(MODEL_SIZE, device="cuda", compute_type="float16")
    except Exception:
        pass

    # CPU path
    for ct in ("int8", "float32"):
        try:
            print(f"[model] CPU â†’ compute_type={ct}")
            return WhisperModel(MODEL_SIZE, device="cpu", compute_type=ct)
        except Exception as e:
            print(f"[model] {ct} failed: {e}")
    # last resort
    return WhisperModel(MODEL_SIZE, device="cpu")

def list_inputs():
    print("\n[devices] input devices:")
    for i, d in enumerate(sd.query_devices()):
        if d["max_input_channels"] > 0:
            print(f"  #{i}: {d['name']}  (default_sr={int(d['default_samplerate'])})")
    print(f"[devices] default input index: {sd.default.device[0]}\n")

def audio_callback(indata, frames, time_info, status):
    if status:
        print("âš ï¸", status)
    # int16 â†’ float32 [-1,1]
    f32 = (indata[:, 0].astype(np.float32) / 32768.0).copy()
    q.put(f32)

def stt_loop(model: WhisperModel):
    """
    à¦•à¦¿à¦‰ à¦¥à§‡à¦•à§‡ à¦…à¦¡à¦¿à¦“ à¦¨à¦¿à§Ÿà§‡ à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦­à§à¦¯à¦¾à¦²à§‡ à¦Ÿà§à¦°à¦¾à¦¨à§à¦¸à¦•à§à¦°à¦¾à¦‡à¦¬ à¦•à¦°à§‡ à¦ªà§à¦°à¦¿à¦¨à§à¦Ÿ à¦•à¦°à¦¬à§‡à¥¤
    """
    buf = np.zeros(0, dtype=np.float32)
    last_process = 0.0
    last_print = ""

    while running[0]:
        # à¦•à¦¿à¦‰ à¦¥à§‡à¦•à§‡ à¦¨à¦¤à§à¦¨ à¦«à§à¦°à§‡à¦® à¦œà§‹à§œà¦¾ à¦²à¦¾à¦—à¦¾à¦‡
        try:
            chunk = q.get(timeout=0.1)
            buf = np.concatenate([buf, chunk])
            # à¦°à§‹à¦²à¦¿à¦‚ à¦‰à¦‡à¦¨à§à¦¡à§‹ à¦°à§‡à¦–à§‡ à¦¦à¦¿à¦‡
            max_len = int((ROLLING_WINDOW_SEC + 1.0) * SAMPLE_RATE)
            if buf.size > max_len:
                buf = buf[-max_len:]
        except queue.Empty:
            pass

        now = time.time()
        if now - last_process < PROCESS_EVERY_SEC:
            continue
        last_process = now

        if buf.size < int(0.5 * SAMPLE_RATE):
            continue  # à¦…à¦¤à¦¿ à¦›à§‹à¦Ÿ à¦¹à¦²à§‡ à¦¸à§à¦•à¦¿à¦ª

        # à¦–à§à¦¬ à¦¦à§à¦°à§à¦¤ à¦¸à§‡à¦Ÿà¦¿à¦‚à¦¸: beam_size=1, temperature=0.0
        segments, info = model.transcribe(
            buf,
            beam_size=1,
            temperature=0.0,
            vad_filter=False,                 # à¦šà¦¾à¦‡à¦²à§‡ True à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨
            condition_on_previous_text=False,
            language=LANGUAGE,                # None=auto, à¦¬à¦¾ "bn"/"en"
            word_timestamps=False,
        )

        text = " ".join(s.text.strip() for s in segments if s.text.strip()).strip()
        if text and text != last_print:
            print("ðŸ‘‰", text)
            last_print = text

if __name__ == "__main__":
    # à¦®à¦¾à¦‡à¦• à¦¡à¦¿à¦­à¦¾à¦‡à¦¸ à¦²à¦¿à¦¸à§à¦Ÿ à¦¦à§‡à¦–à¦¾à¦‡ (à¦ªà¦¾à¦°à¦®à¦¿à¦¶à¦¨ à¦‡à¦¸à§à¦¯à§ à¦¹à¦²à§‡ à¦à¦–à¦¾à¦¨à§‡à¦‡ à¦§à¦°à¦¾ à¦ªà§œà¦¬à§‡)
    try:
        list_inputs()
    except Exception as e:
        print("âŒ à¦®à¦¾à¦‡à¦• à¦²à¦¿à¦¸à§à¦Ÿ à¦•à¦°à¦¾ à¦¯à¦¾à§Ÿà¦¨à¦¿:", e)
        print("âž¡ï¸ macOS: System Settings â†’ Privacy & Security â†’ Microphone â†’ à¦†à¦ªà¦¨à¦¾à¦° Terminal/iTerm/VSCode-à¦•à§‡ Allow à¦•à¦°à§‡ à¦¦à¦¿à¦¨, à¦¤à¦¾à¦°à¦ªà¦° à¦Ÿà¦¾à¦°à§à¦®à¦¿à¦¨à¦¾à¦² à¦°à¦¿à¦¸à§à¦Ÿà¦¾à¦°à§à¦Ÿ à¦•à¦°à§à¦¨à¥¤")
        raise

    # à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡
    model = load_model()

    # à¦•à¦¿à¦‰ + à¦¥à§à¦°à§‡à¦¡
    q: "queue.Queue[np.ndarray]" = queue.Queue()
    running = [True]
    worker = threading.Thread(target=stt_loop, args=(model,), daemon=True)
    worker.start()

    # à¦‡à¦¨à¦ªà§à¦Ÿ à¦¸à§à¦Ÿà§à¦°à¦¿à¦® à¦–à§à¦²à§‡ à¦¦à¦¿à¦‡
    blocksize = int(SAMPLE_RATE * (FRAME_MS / 1000.0))
    print("ðŸŽ¤ à¦¬à¦²à§à¦¨ (Ctrl+C à¦šà¦¾à¦ªà¦²à§‡ à¦¬à¦¨à§à¦§ à¦¹à¦¬à§‡)â€¦")
    try:
        with sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype="int16",
            blocksize=blocksize,
            callback=audio_callback,
        ):
            while True:
                time.sleep(0.2)
    except KeyboardInterrupt:
        print("\nðŸ›‘ à¦¬à¦¨à§à¦§ à¦•à¦°à¦¾ à¦¹à¦²à¥¤")
    finally:
        running[0] = False
        worker.join(timeout=1.0)
