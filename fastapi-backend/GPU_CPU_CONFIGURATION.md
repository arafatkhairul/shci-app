# GPU/CPU Configuration for Piper TTS

‡¶è‡¶á ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡ßá **Piper TTS** ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡ßç‡¶¨‡¶Ø‡¶º‡¶Ç‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º GPU/CPU detection ‡¶è‡¶¨‡¶Ç configuration ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§

## üéØ Auto-Detection Logic

### Environment-Based Detection:
- **Local Environment**: CPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá (‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ startup)
- **Production Environment**: GPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá (‡¶â‡¶ö‡ßç‡¶ö performance)

### Manual Override Options:
- **Force CPU**: ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã environment ‡¶è CPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
- **Force GPU**: ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã environment ‡¶è GPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®

## üîß Configuration Options

### Environment Variables:

```bash
# Environment Detection
TTS_ENVIRONMENT=local          # CPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá
TTS_ENVIRONMENT=production    # GPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá (‡¶Ø‡¶¶‡¶ø available ‡¶π‡¶Ø‡¶º)

# Manual Device Selection
PIPER_DEVICE=cuda            # Force GPU
PIPER_DEVICE=cpu             # Force CPU

# Force Override
PIPER_FORCE_CUDA=true        # Force GPU even in local
PIPER_FORCE_CPU=true         # Force CPU even in production
```

### Configuration Examples:

#### Local Development (CPU):
```bash
export TTS_ENVIRONMENT=local
# Auto-detected: CPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá
```

#### Production Server (GPU):
```bash
export TTS_ENVIRONMENT=production
# Auto-detected: GPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá (‡¶Ø‡¶¶‡¶ø available ‡¶π‡¶Ø‡¶º)
```

#### Force CPU in Production:
```bash
export TTS_ENVIRONMENT=production
export PIPER_FORCE_CPU=true
# Force: CPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá
```

#### Force GPU in Local:
```bash
export TTS_ENVIRONMENT=local
export PIPER_FORCE_CUDA=true
# Force: GPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá (‡¶Ø‡¶¶‡¶ø available ‡¶π‡¶Ø‡¶º)
```

## üìä Device Information

### TTS Info API:
```bash
curl http://localhost:8000/tts/info
```

Response:
```json
{
  "tts_system": "Piper TTS",
  "info": {
    "providers": {
      "piper": {
        "device_config": {
          "use_cuda": false,
          "device_type": "CPU",
          "device_name": "CPU",
          "cuda_available": false,
          "cuda_device_count": 0
        }
      }
    }
  }
}
```

### Health Check API:
```bash
curl http://localhost:8000/tts/health
```

Response:
```json
{
  "status": "healthy",
  "tts_system": "piper",
  "available_providers": ["piper", "fallback"],
  "environment": "local"
}
```

## üöÄ Performance Comparison

### CPU Mode (Local):
- **Startup Time**: ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§
- **Memory Usage**: ‡¶ï‡¶Æ
- **Synthesis Speed**: ‡¶Æ‡¶æ‡¶ù‡¶æ‡¶∞‡¶ø
- **Best For**: Development, testing

### GPU Mode (Production):
- **Startup Time**: ‡¶ß‡ßÄ‡¶∞ (model loading)
- **Memory Usage**: ‡¶¨‡ßá‡¶∂‡¶ø
- **Synthesis Speed**: ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§
- **Best For**: Production, high load

## üîç CUDA Detection

### Automatic Detection:
1. **PyTorch Check**: `torch.cuda.is_available()`
2. **Device Count**: `torch.cuda.device_count()`
3. **Device Name**: `torch.cuda.get_device_name(0)`

### Fallback Behavior:
- CUDA unavailable ‚Üí CPU ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá
- GPU loading failed ‚Üí CPU fallback
- Manual override ‚Üí ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü device ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá

## üìù Logging

### Device Detection Logs:
```
üîß Device: CPU (CPU)
üîß CUDA: Disabled
[DEVICE] Using CPU
[OK] Model loaded successfully with CPU
```

### GPU Mode Logs:
```
üîß Device: GPU (NVIDIA GeForce RTX 3080)
üîß CUDA: Enabled
[DEVICE] Using GPU
[OK] Model loaded successfully with GPU acceleration
```

## üõ†Ô∏è Troubleshooting

### Common Issues:

1. **CUDA Not Available**:
   ```
   ‚ö†Ô∏è CUDA not available - using CPU
   ```
   **Solution**: Install CUDA toolkit or use CPU mode

2. **GPU Loading Failed**:
   ```
   GPU loading failed, falling back to CPU
   ```
   **Solution**: Check GPU memory or use CPU mode

3. **Manual Override Not Working**:
   ```
   üîß Force CPU enabled
   ```
   **Solution**: Check environment variables

### Debug Commands:

```bash
# Check CUDA availability
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# Check device info
python -c "from tts_factory import get_tts_info; import json; print(json.dumps(get_tts_info()['providers']['piper']['device_config'], indent=2))"

# Test synthesis
python -c "from tts_factory import synthesize_text; audio = synthesize_text('Test', 'en'); print(f'Synthesis: {len(audio)} bytes')"
```

## üéØ Best Practices

### Development:
```bash
export TTS_ENVIRONMENT=local
# Fast startup, CPU usage
```

### Production:
```bash
export TTS_ENVIRONMENT=production
# High performance, GPU usage (if available)
```

### Docker:
```bash
# CPU-only container
export PIPER_FORCE_CPU=true

# GPU-enabled container
export PIPER_FORCE_CUDA=true
```

## üìà Monitoring

### Performance Metrics:
- **Synthesis Time**: Monitor via logs
- **Memory Usage**: Check system resources
- **GPU Utilization**: Use `nvidia-smi`

### Health Checks:
- **TTS Health**: `/tts/health`
- **Device Status**: `/tts/info`
- **Synthesis Test**: `/test-tts`

---

**Note**: ‡¶è‡¶á configuration system ‡¶∏‡ßç‡¶¨‡¶Ø‡¶º‡¶Ç‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶≠‡¶æ‡¶¨‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ environment detect ‡¶ï‡¶∞‡ßá ‡¶è‡¶¨‡¶Ç optimal device select ‡¶ï‡¶∞‡ßá‡•§ Manual override options ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶∏‡¶Æ‡¶Ø‡¶º device change ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®‡•§
