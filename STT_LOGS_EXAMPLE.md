# ğŸ¤ Server-side STT Logs Example

## STT Processing Pipeline Logs

When you speak into the microphone, you'll see these logs in the server console:

### 1. Audio Data Reception
```
[connection_id] ğŸ¤ Audio data received: 1920 bytes
[connection_id] ğŸ¤ Audio data received: 1920 bytes
[connection_id] ğŸ¤ Audio data received: 1920 bytes
```

### 2. Audio Buffer Management
```
ğŸ¤ Audio buffer: 16000 samples, 1.00s duration
ğŸ¤ Audio buffer: 32000 samples, 2.00s duration
ğŸ¤ Audio buffer: 48000 samples, 3.00s duration
```

### 3. STT Processing Start
```
[connection_id] ğŸ¤ Buffer ready for STT: 1.25s
ğŸ¤ STT Processing: 20000 samples, 1.25s duration
ğŸ¤ Audio stats: RMS=0.1234, Max=0.5678
ğŸ¤ Starting WhisperX transcription...
```

### 4. WhisperX Transcription
```
ğŸ¤ STT Complete: 2 segments in 0.85s
ğŸ¤ Segment 1: 'hello' (conf: -0.23, 0.00s-0.50s)
ğŸ¤ Segment 2: 'how are you' (conf: -0.15, 0.50s-1.25s)
```

### 5. WebSocket Response
```
[connection_id] ğŸ¤ STT Result: 'hello how are you' (confidence: -0.15)
[connection_id] ğŸ“¤ Sent interim transcript to client
[connection_id] ğŸ“¤ Sent final transcript to client
```

### 6. AI Processing
```
[connection_id] ğŸ“ Processing transcript: hello how are you
[connection_id] ğŸ”„ LLM streaming request to http://69.197.183.130:11434/v1/chat/completions
[connection_id] ğŸ“¡ LLM streaming API response status: 200
```

## Log Levels

- **INFO**: Main STT processing steps
- **DEBUG**: Detailed audio statistics and buffer management
- **ERROR**: STT processing errors

## Monitoring Commands

```bash
# Monitor STT logs
./monitor-stt-logs.sh

# Check server status
ps aux | grep "python main.py"

# View real-time logs
cd fastapi-backend && python main.py
```

## Expected Log Flow

1. **Audio Reception** â†’ Audio data received from frontend
2. **Buffer Management** â†’ Audio samples accumulated
3. **STT Trigger** â†’ Buffer reaches 1 second minimum
4. **WhisperX Processing** â†’ Server-side transcription
5. **Result Processing** â†’ Text extraction and confidence scoring
6. **WebSocket Response** â†’ Send transcript to frontend
7. **AI Processing** â†’ Generate response using LLM

## Troubleshooting

- **No audio data**: Check microphone permissions
- **Buffer not ready**: Wait for 1 second of audio
- **No transcription**: Check WhisperX model loading
- **Empty results**: Check audio quality and language settings
